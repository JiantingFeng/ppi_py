{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f04e65-56dc-457c-8129-c8dc49b36c4f",
   "metadata": {},
   "source": [
    "# Relationship between age and income\n",
    "\n",
    "The goal is to investigate the relationship between age and income using US census data. The target of inference is the linear regression coefficient when regressing yearly income in dollars on age, while controlling for sex. The data from California in the year 2019 is downloaded through the Folktables interface (1). Predictions of income are made by training a gradient boosting tree via XGBoost (2) on the previous year’s data.\n",
    "\n",
    "1. F. Ding, M. Hardt, J. Miller, L. Schmidt, “Retiring adult: New datasets for fair machine learning” in Advances in Neural Information Processing Systems 34 (2021), pp. 6478–6490.\n",
    "2. T. Chen, C. Guestrin, “XGBoost: A scalable tree boosting system” in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2016), pp. 785–794."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d677d1-9c49-40ca-9d8b-4ad2541b013c",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c21cbbe-ccb0-4d54-b913-41c88c9d08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ppi_py.datasets import load_dataset\n",
    "from ppi_py import ppi_ols_ci, classical_ols_ci\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from scipy.optimize import brentq\n",
    "from tqdm import tqdm\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf90ae6",
   "metadata": {},
   "source": [
    "### Import the census income data set\n",
    "\n",
    "Load the data. The data set contains reported income (```Y```), predicted income (```Yhat```), and age and sex (```X```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6da3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"./data/\"\n",
    "data = load_dataset(dataset_folder, \"census_income\")\n",
    "Y_total = data[\"Y\"]\n",
    "Yhat_total = data[\"Yhat\"]\n",
    "X_total = data[\"X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969f9db",
   "metadata": {},
   "source": [
    "### Problem setup\n",
    "\n",
    "Specify the error level (```alpha```), range of values for the labeled data set size (```ns```), and number of trials (```num_trials```).\n",
    "\n",
    "Compute the ground-truth value of the estimand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3c8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "coordinate = 0  # Choose between 0, 1\n",
    "n_total = Y_total.shape[0]  # Total number of labeled examples\n",
    "ns = np.linspace(100, 2000, 10).astype(\n",
    "    int\n",
    ")  # Test for different numbers of labeled incomes\n",
    "num_trials = 100\n",
    "# Compute ground truth\n",
    "true_theta = OLS(Y_total, exog=X_total).fit().params[coordinate]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce18be",
   "metadata": {},
   "source": [
    "### Construct intervals\n",
    "\n",
    "Form confidence intervals for all methods and problem parameters. A dataframe with the following columns is formed:\n",
    "1. ```method``` (one of ```PPI```, ```Classical```, and ```Imputation```)\n",
    "2. ```n``` (labeled data set size, takes values in ```ns```)\n",
    "3. ```lower``` (lower endpoint of the confidence interval)\n",
    "4. ```upper``` (upper endpoint of the confidence interval)\n",
    "5. ```trial``` (index of trial, goes from ```0``` to ```num_trials-1```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f8fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [01:56<17:29, 116.60s/it]"
     ]
    }
   ],
   "source": [
    "# Run prediction-powered inference and classical inference for many values of n\n",
    "results = []\n",
    "for i in tqdm(range(ns.shape[0])):\n",
    "    for j in range(num_trials):\n",
    "        # Prediction-Powered Inference\n",
    "        n = ns[i]\n",
    "        rand_idx = np.random.permutation(n_total)\n",
    "        _X, _X_unlabeled = X_total[rand_idx[:n]], X_total[rand_idx[n:]]\n",
    "        _Y, _Y_unlabeled = Y_total[rand_idx[:n]], Y_total[rand_idx[n:]]\n",
    "        _Yhat, _Yhat_unlabeled = (\n",
    "            Yhat_total[rand_idx[:n]],\n",
    "            Yhat_total[rand_idx[n:]],\n",
    "        )\n",
    "\n",
    "        ppi_ci = ppi_ols_ci(\n",
    "            _X, _Y, _Yhat, _X_unlabeled, _Yhat_unlabeled, alpha=alpha\n",
    "        )\n",
    "\n",
    "        # Classical interval\n",
    "        classical_ci = classical_ols_ci(_X, _Y, alpha=alpha)\n",
    "\n",
    "        # Append results\n",
    "        results += [\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"method\": \"PPI\",\n",
    "                        \"n\": n,\n",
    "                        \"lower\": ppi_ci[0][coordinate],\n",
    "                        \"upper\": ppi_ci[1][coordinate],\n",
    "                        \"trial\": j,\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "        results += [\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"method\": \"Classical\",\n",
    "                        \"n\": n,\n",
    "                        \"lower\": classical_ci[0][coordinate],\n",
    "                        \"upper\": classical_ci[1][coordinate],\n",
    "                        \"trial\": j,\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "# Imputed CI\n",
    "imputed_ci = classical_ols_ci(X_total, Yhat_total, alpha=alpha)\n",
    "results += [\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"method\": \"Imputation\",\n",
    "                \"n\": np.nan,\n",
    "                \"lower\": imputed_ci[0][coordinate],\n",
    "                \"upper\": imputed_ci[1][coordinate],\n",
    "                \"trial\": 0,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "df = pd.concat(results, axis=0, ignore_index=True)\n",
    "df[\"width\"] = df[\"upper\"] - df[\"lower\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ba288",
   "metadata": {},
   "source": [
    "### Plot results\n",
    "\n",
    "Plot:\n",
    "1. Five randomly chosen intervals from the dataframe for PPI and the classical method, and the imputed interval;\n",
    "2. The average interval width for PPI and the classical method, together with a scatterplot of the widths from the five random draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(\n",
    "    df,\n",
    "    \"./plots/census_income.pdf\",\n",
    "    intervals_xlabel=\"OLS coeff\",\n",
    "    true_theta=true_theta,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e8f41-d4e6-40a5-b4e3-e071f0f38d46",
   "metadata": {},
   "source": [
    "### Power experiment\n",
    "\n",
    "For PPI and the classical approach, find the smallest value of ```n``` such that the method has power 80% against the null $H_0: \\theta^* < 800$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find n such that we reject H0: OLS coeff < 800 with probability 80% using a test at level alpha\n",
    "num_experiments = 100\n",
    "list_rand_idx = [\n",
    "    np.random.permutation(n_total) for i in range(num_experiments)\n",
    "]\n",
    "\n",
    "\n",
    "def _to_invert_ppi(n):\n",
    "    n = int(n)\n",
    "    nulls_rejected = 0\n",
    "    # Data setup\n",
    "    for i in range(num_experiments):\n",
    "        rand_idx = list_rand_idx[i]\n",
    "        _X, _X_unlabeled = X_total[rand_idx[:n]], X_total[rand_idx[n:]]\n",
    "        _Y, _Y_unlabeled = Y_total[rand_idx[:n]], Y_total[rand_idx[n:]]\n",
    "        _Yhat, _Yhat_unlabeled = (\n",
    "            Yhat_total[rand_idx[:n]],\n",
    "            Yhat_total[rand_idx[n:]],\n",
    "        )\n",
    "\n",
    "        ppi_ci = ppi_ols_ci(\n",
    "            _X, _Y, _Yhat, _X_unlabeled, _Yhat_unlabeled, alpha=alpha\n",
    "        )\n",
    "\n",
    "        if ppi_ci[0][coordinate] > 800:\n",
    "            nulls_rejected += 1\n",
    "    return nulls_rejected / num_experiments - 0.8\n",
    "\n",
    "\n",
    "def _to_invert_classical(n):\n",
    "    n = int(n)\n",
    "    nulls_rejected = 0\n",
    "    # Data setup\n",
    "    for i in range(num_experiments):\n",
    "        rand_idx = list_rand_idx[i]\n",
    "        _X, _X_unlabeled = X_total[rand_idx[:n]], X_total[rand_idx[n:]]\n",
    "        _Y, _Y_unlabeled = Y_total[rand_idx[:n]], Y_total[rand_idx[n:]]\n",
    "        _Yhat, _Yhat_unlabeled = (\n",
    "            Yhat_total[rand_idx[:n]],\n",
    "            Yhat_total[rand_idx[n:]],\n",
    "        )\n",
    "\n",
    "        classical_ci = classical_ols_ci(_X, _Y, alpha=alpha)\n",
    "\n",
    "        if classical_ci[0][coordinate] > 800:\n",
    "            nulls_rejected += 1\n",
    "    return nulls_rejected / num_experiments - 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ppi = int(brentq(_to_invert_ppi, 100, 2000, xtol=1))\n",
    "n_classical = int(brentq(_to_invert_classical, 100, 2000, xtol=1))\n",
    "print(\n",
    "    f\"The PPI test requires n={n_ppi} labeled data points to reject the null.\"\n",
    ")\n",
    "print(\n",
    "    f\"The classical test requires n={n_classical} labeled data points to reject the null.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
